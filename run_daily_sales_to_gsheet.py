import os
import re
import json
import ast
import subprocess
import logging
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional, Tuple

import gspread
from google.oauth2.service_account import Credentials
from dotenv import load_dotenv

# âœ… Slack ì „ì†¡(ì›¹í›…) ì¶”ê°€
import requests

KST = timezone(timedelta(hours=9))
LOGGER = logging.getLogger("daily_sales")

SPREADSHEET_ID = "1DeSRVN4pWf6rnp1v_FeePUYe1ngjwyq_znXZUzl_kbM"
SHEET_BURDENZERO = "ë¶€ë‹´ì œë¡œ"
SHEET_BRAINOLOGY = "ë‰´í„´ì ¤ë¦¬"

# âœ… í•´ê²° 1: Playwright temp ê²½ë¡œë¥¼ ì•ˆì •ì ìœ¼ë¡œ ê³ ì •
SAFE_TEMP_DIR = r"C:\Temp"


@dataclass
class DailyMetrics:
    sales: int
    orders: int


def yday_kst_date():
    return (datetime.now(KST) - timedelta(days=1)).date()


# ---------------------------
# Google Sheets
# ---------------------------
def gspread_client_from_service_account() -> gspread.Client:
    sa_path = os.getenv("GOOGLE_SA_JSON")
    if not sa_path or not os.path.exists(sa_path):
        raise RuntimeError(
            "GOOGLE_SA_JSON í™˜ê²½ë³€ìˆ˜ì— ì„œë¹„ìŠ¤ê³„ì • JSON ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤. "
            "ì˜ˆ) GOOGLE_SA_JSON=C:\\keys\\moncgroup-gsheet-sa.json"
        )

    scopes = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]
    creds = Credentials.from_service_account_file(sa_path, scopes=scopes)
    return gspread.authorize(creds)


def find_or_create_row_by_date(ws: gspread.Worksheet, date_str: str) -> int:
    col_a = ws.col_values(1)
    for idx, val in enumerate(col_a, start=1):
        if (val or "").strip() == date_str:
            return idx
    ws.append_row([date_str], value_input_option="USER_ENTERED")
    return len(col_a) + 1


def write_metrics_row(
    ws: gspread.Worksheet,
    row: int,
    cafe24: Optional[DailyMetrics],
    coupang: Optional[DailyMetrics],
    naver: Optional[DailyMetrics],
) -> None:
    # B~G
    values = [
        cafe24.sales if cafe24 else "",
        cafe24.orders if cafe24 else "",
        coupang.sales if coupang else "",
        coupang.orders if coupang else "",
        naver.sales if naver else "",
        naver.orders if naver else "",
    ]
    ws.update(f"B{row}:G{row}", [values], value_input_option="USER_ENTERED")


def write_meta_row(ws: gspread.Worksheet, row: int, spend: Optional[int], purchases: Optional[int]) -> None:
    # J~K
    values = [
        spend if spend is not None else "",
        purchases if purchases is not None else "",
    ]
    ws.update(f"J{row}:K{row}", [values], value_input_option="USER_ENTERED")


# ---------------------------
# âœ… Slack helpers (Webhook) (ì¶”ê°€)
# ---------------------------
def _fmt_krw(n: int) -> str:
    try:
        return f"{int(n):,}ì›"
    except Exception:
        return f"{n}ì›"


def _fmt_int(n: int) -> str:
    try:
        return f"{int(n):,}"
    except Exception:
        return str(n)


def _safe_div(a: float, b: float) -> Optional[float]:
    try:
        if b == 0:
            return None
        return a / b
    except Exception:
        return None


def send_slack_message(text: str) -> None:
    """
    Incoming Webhookìœ¼ë¡œ ì „ì†¡
    í™˜ê²½ë³€ìˆ˜:
      - SLACK_WEBHOOK_URL: https://hooks.slack.com/services/...
    """
    webhook_url = (os.getenv("SLACK_WEBHOOK_URL") or "").strip()
    if not webhook_url:
        LOGGER.warning("Slack ì „ì†¡ ìŠ¤í‚µ: SLACK_WEBHOOK_URL ë¯¸ì„¤ì •")
        return

    try:
        r = requests.post(webhook_url, json={"text": text}, timeout=15)
        if r.status_code < 200 or r.status_code >= 300:
            LOGGER.warning("Slack ì „ì†¡ ì‹¤íŒ¨: status=%s body=%s", r.status_code, (r.text or "")[:500])
        else:
            LOGGER.info("âœ… Slack ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        LOGGER.warning("Slack ì „ì†¡ ì˜ˆì™¸: %s", e)


def build_slack_summary(
    brand_label: str,
    date_str: str,
    total_sales: int,
    total_orders: int,
    meta_spend: int,
) -> str:
    roas = _safe_div(total_sales, meta_spend)
    cpa = _safe_div(meta_spend, total_orders)

    roas_txt = f"{roas:.2f}" if roas is not None else "N/A"
    cpa_txt = _fmt_krw(int(cpa)) if cpa is not None else "N/A"

    return (
        f"ğŸ“Œ {brand_label} ì–´ì œ ì„±ê³¼ ({date_str})\n"
        f"(ìì‚¬ëª°, ì¿ íŒ¡, ë„¤ì´ë²„, ë©”íƒ€ ê´‘ê³ ë¹„ë§Œ ì¡°íšŒ)\n"
        f"â€¢ ë§¤ì¶œ {_fmt_krw(total_sales)} / {_fmt_int(total_orders)}ê±´\n"
        f"â€¢ ROAS {roas_txt} / CPA: {cpa_txt}\n"
        f"â€¢ ë©”íƒ€ ê´‘ê³ ë¹„: {_fmt_krw(meta_spend)}\n"

    )


# ---------------------------
# Subprocess JSON parsing
# ---------------------------
def _extract_last_object(text: str) -> Dict[str, Any]:
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    if not lines:
        raise RuntimeError("stdoutì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    for ln in reversed(lines):
        if ln.startswith("{") and ln.endswith("}"):
            try:
                return json.loads(ln)
            except Exception:
                pass
            try:
                return ast.literal_eval(ln)
            except Exception:
                pass

        if "{" in ln and "}" in ln:
            m = re.search(r"(\{.*\})", ln)
            if m:
                chunk = m.group(1)
                try:
                    return json.loads(chunk)
                except Exception:
                    pass
                try:
                    return ast.literal_eval(chunk)
                except Exception:
                    pass

    raise RuntimeError("stdoutì—ì„œ íŒŒì‹± ê°€ëŠ¥í•œ JSON/dict ê°ì²´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


def run_script(script_path: str, args: List[str]) -> Dict[str, Any]:
    """
    âœ… í•´ê²° 1 ì ìš© (ì›ë³¸ êµ¬ì¡° ìœ ì§€ + ìµœì†Œ ë³€ê²½)
    - ì„œë¸Œí”„ë¡œì„¸ìŠ¤ì— TEMP/TMPë¥¼ C:\\Tempë¡œ ê°•ì œ ì „ë‹¬ â†’ Playwright mkdtemp ENOENT ë°©ì§€
    - ì„œë¸Œí”„ë¡œì„¸ìŠ¤ì— UTF-8 ê°•ì œ â†’ UnicodeEncodeError(charmap) ë°©ì§€
    """
    # TEMP í´ë”ê°€ ì—†ìœ¼ë©´ íŒŒì´ì¬ì—ì„œ ìƒì„± (CMD/ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œë„ ì•ˆì „)
    os.makedirs(SAFE_TEMP_DIR, exist_ok=True)

    env = os.environ.copy()

    # 1) Playwright artifacts temp ì•ˆì •í™”
    env["TEMP"] = SAFE_TEMP_DIR
    env["TMP"] = SAFE_TEMP_DIR

    # 2) Windows ì½˜ì†” ì¸ì½”ë”© ì´ìŠˆ ë°©ì§€ (ì„œë¸Œí”„ë¡œì„¸ìŠ¤ íŒŒì´ì¬ ì¶œë ¥ UTF-8 ê°•ì œ)
    env["PYTHONUTF8"] = "1"
    env["PYTHONIOENCODING"] = "utf-8"

    cmd = ["python", script_path] + args
    LOGGER.info("RUN: %s", " ".join(cmd))

    p = subprocess.run(
        cmd,
        capture_output=True,
        text=True,
        encoding="utf-8",
        env=env,  # âœ… í•µì‹¬: ì„œë¸Œí”„ë¡œì„¸ìŠ¤ì— í™˜ê²½ë³€ìˆ˜ ì „ë‹¬
    )

    if p.returncode != 0:
        raise RuntimeError(
            f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤íŒ¨: {script_path}\nSTDOUT:\n{p.stdout}\nSTDERR:\n{p.stderr}"
        )
    return _extract_last_object(p.stdout)


# ---------------------------
# Normalize channel payloads
# ---------------------------
def metrics_from_simple(payload: Dict[str, Any]) -> DailyMetrics:
    return DailyMetrics(int(payload.get("sales", 0) or 0), int(payload.get("orders", 0) or 0))


def metrics_from_coupang(payload: Dict[str, Any]) -> Dict[str, DailyMetrics]:
    """
    ì¿ íŒ¡ payloadëŠ” coupang.py ìˆ˜ì •ë³¸ ê¸°ì¤€:
      payload["mapped"]["burdenzero"] / ["brainology"] / ["ppadi"]
    """
    mapped = payload.get("mapped") or {}
    bz = mapped.get("burdenzero") or {}
    br = mapped.get("brainology") or {}

    return {
        "burdenzero": DailyMetrics(int(bz.get("sales", 0) or 0), int(bz.get("orders", 0) or 0)),
        "brainology": DailyMetrics(int(br.get("sales", 0) or 0), int(br.get("orders", 0) or 0)),
    }


def _as_int(v: Any) -> int:
    try:
        if v is None:
            return 0
        if isinstance(v, (int, float)):
            return int(v)
        s = str(v).strip()
        if not s:
            return 0
        s = re.sub(r"[^\d\-]", "", s)
        return int(s) if s else 0
    except Exception:
        return 0


def _pick_first(d: Dict[str, Any], keys: List[str]) -> Any:
    for k in keys:
        if k in d and d.get(k) is not None:
            return d.get(k)
    return None


def metrics_from_meta_ads(payload: Dict[str, Any]) -> Dict[str, Tuple[int, int]]:
    """
    meta_ads.py ì¶œë ¥ í¬ë§·ì´ ê³„ì •/ì½”ë“œì— ë”°ë¼ ì¡°ê¸ˆ ë‹¬ë¼ë„ ê²¬ë”œ ìˆ˜ ìˆê²Œ ë„“ê²Œ íŒŒì‹±.
    ê¸°ëŒ€: ë¶€ë‹´ì œë¡œ/ë¸Œë ˆì¸ì˜¬ë¡œì§€ ê°ê° ê´‘ê³ ë¹„(spend)ì™€ êµ¬ë§¤ìˆ˜(purchases)

    ì§€ì›í•˜ëŠ” í”í•œ í˜•íƒœ:
      1) {"mapped": {"burdenzero": {"spend":..., "purchases":...}, "brainology": {...}}}
      2) {"burdenzero": {"spend":..., "purchases":...}, "brainology": {...}}
      3) {"brands": {"burdenzero": {...}, "brainology": {...}}}
    í‚¤ í›„ë³´:
      - spend: spend, cost, amount_spent, ad_spend, spend_krw, cost_krw
      - purchases: purchases, purchase, orders, results, conversions, purchase_count
    """
    root = payload
    for k in ("mapped", "brands", "by_brand", "data"):
        if isinstance(root, dict) and isinstance(root.get(k), dict):
            root = root.get(k)
            break

    def parse_brand(d: Dict[str, Any]) -> Tuple[int, int]:
        spend_raw = _pick_first(
            d,
            ["spend", "amount_spent", "ad_spend", "cost", "spend_krw", "cost_krw"],
        )
        purch_raw = _pick_first(
            d,
            ["purchases", "purchase", "purchase_count", "orders", "results", "conversions"],
        )
        return (_as_int(spend_raw), _as_int(purch_raw))

    bz = root.get("burdenzero") if isinstance(root, dict) else None
    br = root.get("brainology") if isinstance(root, dict) else None

    # í˜¹ì‹œ ëŒ€ë¬¸ì/í•œê¸€ í‚¤ë¡œ ì˜¤ëŠ” ê²½ìš°ë„ ëŒ€ë¹„
    if bz is None:
        bz = root.get("ë¶€ë‹´ì œë¡œ") if isinstance(root, dict) else None
    if br is None:
        br = root.get("ë¸Œë ˆì¸ì˜¬ë¡œì§€") if isinstance(root, dict) else None

    bz_spend, bz_purch = (0, 0)
    br_spend, br_purch = (0, 0)

    if isinstance(bz, dict):
        bz_spend, bz_purch = parse_brand(bz)
    if isinstance(br, dict):
        br_spend, br_purch = parse_brand(br)

    return {
        "burdenzero": (bz_spend, bz_purch),
        "brainology": (br_spend, br_purch),
    }


def main():
    load_dotenv()
    logging.basicConfig(
        level=os.getenv("LOG_LEVEL", "INFO"),
        format="%(asctime)s | %(levelname)s | %(message)s",
    )

    target_date = yday_kst_date()
    date_str = target_date.isoformat()
    LOGGER.info("Target date (KST): %s", date_str)

    # paths
    cafe24_path = os.path.join("connectors", "sales", "cafe24.py")
    coupang_path = os.path.join("connectors", "sales", "coupang.py")
    naver_path = os.path.join("connectors", "sales", "naver.py")
    meta_ads_path = os.path.join("connectors", "ads", "meta_ads.py")

    # 1) Cafe24 two accounts
    cafe_bz_payload = run_script(cafe24_path, ["--profile", "burdenzero", "--date", date_str])
    cafe_br_payload = run_script(cafe24_path, ["--profile", "brainology", "--date", date_str])

    cafe_bz = metrics_from_simple(cafe_bz_payload)
    cafe_br = metrics_from_simple(cafe_br_payload)

    # 2) Coupang mixed -> mapped already
    coupang_payload = run_script(coupang_path, ["--date", date_str, "--json"])
    coupang = metrics_from_coupang(coupang_payload)
    coupang_bz = coupang["burdenzero"]
    coupang_br = coupang["brainology"]

    # 3) Naver (burdenzero only)
    naver_payload = run_script(naver_path, ["--date", date_str, "--json"])
    naver_bz = metrics_from_simple(naver_payload)

    # 4) Meta Ads (burdenzero + brainology)
    meta_payload = run_script(meta_ads_path, ["--date", date_str, "--json"])
    meta = metrics_from_meta_ads(meta_payload)
    meta_bz_spend, meta_bz_purchases = meta["burdenzero"]
    meta_br_spend, meta_br_purchases = meta["brainology"]

    # 5) Write to Google Sheets
    gc = gspread_client_from_service_account()
    sh = gc.open_by_key(SPREADSHEET_ID)

    ws_bz = sh.worksheet(SHEET_BURDENZERO)
    ws_br = sh.worksheet(SHEET_BRAINOLOGY)

    row_bz = find_or_create_row_by_date(ws_bz, date_str)
    row_br = find_or_create_row_by_date(ws_br, date_str)

    # ë¶€ë‹´ì œë¡œ: B~G ëª¨ë‘
    write_metrics_row(ws_bz, row_bz, cafe24=cafe_bz, coupang=coupang_bz, naver=naver_bz)
    # ë‰´í„´ì ¤ë¦¬: ì¹´í˜24/ì¿ íŒ¡ë§Œ, ë„¤ì´ë²„ëŠ” ì—†ìŒ
    write_metrics_row(ws_br, row_br, cafe24=cafe_br, coupang=coupang_br, naver=None)

    # ë©”íƒ€ ê´‘ê³ ë¹„/êµ¬ë§¤ìˆ˜: J~K
    write_meta_row(ws_bz, row_bz, spend=meta_bz_spend, purchases=meta_bz_purchases)
    write_meta_row(ws_br, row_br, spend=meta_br_spend, purchases=meta_br_purchases)

    # âœ… Slack ìš”ì•½ ì „ì†¡ (ì¶”ê°€: ì‹œíŠ¸ ì‘ì„± ì´í›„)
    bz_total_sales = cafe_bz.sales + coupang_bz.sales + naver_bz.sales
    bz_total_orders = cafe_bz.orders + coupang_bz.orders + naver_bz.orders

    br_total_sales = cafe_br.sales + coupang_br.sales
    br_total_orders = cafe_br.orders + coupang_br.orders

    send_slack_message(
        build_slack_summary(
            brand_label="ë¶€ë‹´ì œë¡œ",
            date_str=date_str,
            total_sales=bz_total_sales,
            total_orders=bz_total_orders,
            meta_spend=meta_bz_spend,
        )
    )
    send_slack_message(
        build_slack_summary(
            brand_label="ë¸Œë ˆì¸ì˜¬ë¡œì§€",
            date_str=date_str,
            total_sales=br_total_sales,
            total_orders=br_total_orders,
            meta_spend=meta_br_spend,
        )
    )

    LOGGER.info("âœ… Done.")
    LOGGER.info("[ë¶€ë‹´ì œë¡œ] cafe24=%s coupang=%s naver=%s meta(spend=%s,purchases=%s)", cafe_bz, coupang_bz, naver_bz, meta_bz_spend, meta_bz_purchases)
    LOGGER.info("[ë‰´í„´ì ¤ë¦¬] cafe24=%s coupang=%s meta(spend=%s,purchases=%s)", cafe_br, coupang_br, meta_br_spend, meta_br_purchases)


if __name__ == "__main__":
    main()
